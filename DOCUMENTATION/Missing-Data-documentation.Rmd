---
title: "Impute Missing Data with BLIMP"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Overview  

In this method, an input file with missing data is prepped in R and then run through BLIMP, which estimates missing data using multiple imputation and generates an output data set in which all missing cells are replaced with imputed values.

This procedure assumes that data are missing from the input file due to the missing at random (MAR) mechanism. A discussion of missing data theory is beyond the scope of this document, and such knowledge is not needed to use the method described here. Enders (2010) provides a thorough treament of missing data methods and theory.

``` 
Enders, C. K. (2010). Applied Missing Data Analysis. New York: Guilford. 
``` 

The code assumes a typical RStudio project folder hierarchy, with `INPUT-FILES` and `OUTPUT-FILES` folders at the first level.

### Prepare data for BLIMP

Input data should formatted with cases in rows and test items in columns, with a person ID column on the far left. On the input file, items should be renamed as follows: i001, i002, i003, etc. If the input file includes items from different scales/subtests, with different prefixes in their names, those prefixes must be dropped and the items renamed with the `i001` consecutive nomenclature. Do not include any variables in the input file besides the person ID and the item variables.

Once data are in this format, run the next block of R code to restructure the input for BLIMP.

Here and throughout, certain token markers are employed to designate user-input values that vary by project:  

* `{TOKEN}`: any value or series of values  
* `{FILE-PATH}`  
* `{FILE-NAME}` 

###### VALID CODE TO RUN

```{r prep_BLIMP_input, eval=FALSE}
suppressMessages(library(here))
suppressMessages(library(tidyverse))

file_name <- c("{FILE-NAME}")

input_orig <- suppressMessages(read_csv(here(
  str_c("INPUT-FILES/", file_name, ".csv")
))) 

NA_count <- sum(is.na(input_orig))
NA_count

input_orig[is.na(input_orig)] <- 999

input_tall <- input_orig %>%
  pivot_longer(cols = -id,
               names_to = "item",
               values_to = "response") %>%
  mutate(across(item, ~ str_sub(., 2, 4)))

write_csv(input_tall,
          here(
            str_c(file_name, '-BLIMP-input.csv')
            ),
          col_names = F
)
```

###### COMMENTED SNIPPETS
The snippet below contains one user-programmable input paramater. For the token `{FILE-NAME}`, substitute the _prefix_ of input file name (i.e., the file name stripped of `.csv`). Then use `readr::read_csv()` to read the input file into `input_orig`. `here::here()` holds the file path to input file; within `here()`, `stringr::str_c()` concatenates a sequence of string elements into a single string representing the file path.
```{r prep_BLIMP_input, echo=4:8, eval=FALSE}
```
When data are read into R, missing values are coded `NA` (not available). The next snippet counts the `NA` cells across all items and persons in the input table. `is.na()` returns `TRUE` for each table cell containing `NA`. Because logical `TRUE` is equivalent to a numerical code of `1`, `sum()` returns the count of `NA` across all cells. `NA_count` prints this count to the console.
```{r prep_BLIMP_input, echo=10:11, eval=FALSE}
```
Recode the `NA` in the input to `999`, a missing value code typically used by BLIMP. Assign the value `999` to the subset of cells within `input_orig` for which the predicate (logical) expression `is.na(input_orig)` returns `TRUE`.
```{r prep_BLIMP_input, echo=13, eval=FALSE}
```
Recall that the structure of the input file is a row for each case, and a column for each item. The model to be processed by BLIMP requires a multi-level (nested) structure, in which the items and responses are nested within each person. The nested rows contain _name-value pairs_ of items and their associated responses. In the multi-level structure, each person (each unique value of `id`) has the same number of rows as the number of items in the input file. 

Within the set of rows that share an identical value for `id`, the left-right sequence of columns (item names) in the input file is represented in the `item` column, going down the rows. In the `response` column, the response for each item appears in the same row as the item name. The following snippet accomplishes this transformation, from a wide input table to a tall (long) data object.

We use `tidyr::pivot_longer()` to reshape the table. The argument `cols = -id` identifies the columns that are to be changed from wide to long format. Recall that `input_orig` contains only the `id` and the `item` columns. The `-` (minus) operator indicates that `id` is to be _excluded_ from the set of columns to be changed from wide to long. By excluding it in this way, `id` appears as the left-most column in the transformed table, and is "stretched" down the table, creating new duplicate rows for each value of `id`, such that there are the same number of rows for each value of `id` as the number of `item` columns in the input file. 

The argument `names_to = "item"` indicates that the _names_ of the name-value pairs created by `pivot_longer()` will be stored in a column named `item`. The argument `values_to = "response"` indicates that the _values_ of the name-value pairs will be stored in a column named `response`.

In the transformed table, the `item` column contains the `item` names from the input file, repeated anew for (nested within) each successive set of `id` rows. The `response` column contains the item responses for each specific pairing of `id` and `item` values.

To understand how the transformation works, consider the following "before" and "after" examples of a small table containing three cases with responses from a four-item test:

###### Before

ID            | i01           | i02           | i03           | i04
------------- | ------------- | ------------- | ------------- | -------------
1001          | 2             | 2             | 3             | 1
1002          | 4             | 1             | 4             | 2
1003          | 3             | 2             | 3             | 4

###### After

ID            | Item          | Response
------------- | ------------- | -------------
1001          | i01           | 2
1001          | i02           | 2
1001          | i03           | 3
1001          | i04           | 1
1002          | i01           | 4
1002          | i02           | 1
1002          | i03           | 4
1002          | i04           | 2
1003          | i01           | 3
1003          | i02           | 2
1003          | i03           | 3
1003          | i04           | 4

```{r prep_BLIMP_input, echo=15:18, eval=FALSE}
```
BLIMP requires the item names in the `item` column to be numbers, not character strings. We can use `dplyr::mutate()` to make this change. Within `mutate()`, we use `across()` to apply a function to a subset of columns. The first argument specifies that `item` is the column to be modified. The second argument uses the formula shorthand `~` to apply `stringr::str_sub()` to the `item` column. The dot shorthand `.` indicates that `str_sub()` will operate on the previously subsetted column, and `2, 4` indicates that `str_sub()` will extract the numerical portion of the item name (that is, the substring within the name starting at position `2` and ending at position `4`).
```{r prep_BLIMP_input, echo = 19, eval = F}
```
We now use `readr::write_csv` to save the input file for BLIMP as a `.csv`, stripping the column names `col_names = F` as required by BLIMP. The input file is written to the top folder of the RStudio project. The BLIMP
script must also be located in this folder (if it is not, a file path must be specified on the BLIMP `DATA` command).
```{r prep_BLIMP_input, echo = 21:24, eval=FALSE}
```

<br>

### Run BLIMP script on prepped data

After processing in R, the BLIMP input file has the following structure:

* Three columns: Person ID, item number, item response
* The structure is multi-level, in which item-response pairs are nested within each value of Person ID
* No column (variable) names

In simple terms, BLIMP accomplishes the imputation of missing values by estimating a series of linear regression models on the input data. The estimation is an iterative process, whereby BLIMP posits model parameters, derives regression equations, imputes missing data by adding random residual terms to the regression equations, and repeats the process using the newly-imputed data set. Iteration continues for a defined interval to allow regression coefficients to stabilize. The stable regression equations are then used to impute a final complete data set that can be used for downstream analysis.

The model estimation process must include a burn-in phase: a series of iterations that allow the regression parameters to converge (stabilize). The number of iterations required for burn-in varies by data set and is initially unknown. BLIMP supplies a metric for determining convergence: potential scale reduction (PSR). An acceptable burn-in interval is defined as the minimum number of iterations required to yield a PSR value in the range of 1.05-1.10.

The BLIMP imputation process consists of two steps:

1. __Diagnostic Run__: Data are processed with an initial burn-in interval of 1000 iterations. The output table of PSR values is examined, and if PSR is not reduced to 1.05-1.10 by the last set of iterations, the data are re-run with a longer burn-in interval (e.g. 2000 iterations).  This process continues until an acceptable number of burn-in iterations is determined.

2. __Imputation Run__: Data are processed using the burn-in interval determined in Step 1. The saved output data set has all missing responses replaced with imputed values.

An identical BLIMP template script can be used for Steps 1 and 2. This template consists of the following commands (some include values and arguments that remain constant for all input data sets):

```{r BLIMP-template, eval=FALSE}
DATA: {FILE-NAME}.csv
VARIABLES: {TOKEN}
ORDINAL: {TOKEN}
NOMINAL: {TOKEN}
FIXED: {TOKEN}
CLUSTERID: {TOKEN}
MISSING: 999
MODEL: {TOKEN}
SEED: 90291;
BURN: {TOKEN}
ITERATIONS:  1;
OPTIONS: psr;
SAVE: separate = {FILE-NAME}*.csv;
```

Steps 1 and 2 are differentiated by activation/deactivation of the `OPTIONS` and `SAVE` lines (commands can be toggled off by beginning the command line with `#`).

###### Step 1: Diagnostic Run
`OPTIONS` is activated to generate the PSR table. `SAVE` is deactivated because no imputed data set is needed for this step.
```{r BLIMP-multiFactor-template1, eval=FALSE}
OPTIONS: psr;
# SAVE: separate = {FILE-NAME}*.csv;
```
###### Step 2: Imputation Run
`OPTIONS` is deactivated because the burn-in interval has been determined by Step 1, so there is no need to view the PSR table. `SAVE` is activated in order to generate an imputed data set with missing values estimated.
```{r BLIMP-multiFactor-template2, eval=FALSE}
# OPTIONS: psr;
SAVE: separate = {FILE-NAME}*.csv;
```

Below is an example BLIMP script based on this template. The example has a typical set of token substitutions. The file names are generic - any suitable names can be substituted.

###### THIS CODE CAN BE RUN IN BLIMP STUDIO
```{r BLIMP_example, eval=FALSE}
DATA: BLIMP-input.csv;
VARIABLES: id itemnum response;
ORDINAL: response;
NOMINAL: itemnum;
FIXED: itemnum;
CLUSTERID: id;
MISSING: 999;
MODEL: response ~ itemnum;
SEED: 90291;
BURN: 2000; 
ITERATIONS: 1;
OPTIONS: psr;
SAVE: separate = BLIMP-output*.csv;
```

###### COMMENTS
In order to run as written, the `DATA` command must name a file located in the same folder/directory as the BLIMP script. If the input file is located elsewhere, a file path must be specified on `DATA`. Because the input date file has no column names, the `VARIABLES` command is used to name the three columns in the input file: `id`, `itemnum`, `response`. The number of names on the `VARIABLES` line must be identical to the number of columns in the input file.
```{r BLIMP_example, echo=1:2, eval=FALSE}
```
`ORDINAL` and `NOMINAL` are used to designate ordered and non-ordered categorical variables. Here, `response` is listed on the `ORDINAL` line. In the input data file, `response` refers to a 1-2-3-4 item response format; i.e., ordered categories representing increasing frequency of a behavior. On the `NOMINAL` line, `itemnum` represents a non-ordered categorical variable. Variables on the `NOMINAL` line are automatically recoded into dummy codes at imputation.
```{r BLIMP_example, echo=3:4, eval=FALSE}
```
`FIXED` is used to designate variables that will not have their means and variances estimated during computation. Fixing variables in this way increases computational efficiency. In this example, the means and variances of the nominal item number variable are not of substantive interest; thus, there is no reason to estimate these parameters. 

`CLUSTERID` designates a multilevel (nested) design. In this example, on the input file, name-value pairs of `itemnum` and `response` are nested within each value of `id`. `MISSING` identifies the missing data code (`999` was coded in the input file by the R script). 
```{r BLIMP_example, echo=5:7, eval=FALSE}
```
`MODEL` specifies the regression model that will be used for imputation, using formula notation (the `~` symbol) instead of an `=` sign. In choosing a regression model, we consider three factors:

* Rate of "missingness" (percent of cells that are `NA`);
* Accuracy of imputed data sets;
* Computational efficiency.

In general it is best to begin analysis with the most accurate model, and evaluate whether the resulting processing times are acceptable. Multiple imputation is a computationally intensive process and the use of a precise model with a large data set can can result in unacceptably lengthy processing durations.

We can choose from three models, listed here in order of accuracy:

1. `response ~ itemnum`
2. `response ~ scalenum | scalenum`
3. `response ~`

Ideally, we want a model that delivers the most precise imputations, but with large datasets this approach can result in unacceptably lengthy processing durations. When the rate of missingness is low (e.g., < 2%), it is relatively "safe" to sacrifice accuracy in exchange for processing efficiency. In contrast, when the rate of missingness is (e.g., > 20%), we must rely on the most accurate model, and accept the tradeoff in processing time.

Here are recommended regression models to use with three levels of missingness:

Rate of missingness | Recommended model
------------------- | -----------------
< 2%                | `response ~`
2-20%               | `response ~ scalenum | scalenum`
> 20%               | `response ~ itemnum`

This section of commentary covers the `response ~ itemnum` model, which is used in the example script.

On the `MODEL` line in the example script, `response` is regressed on `itemnum`, the dummy-coded item-number variable (recall that dummy code variables were created by listing `itemnum` on the `NOMINAL` command line). 

More specifically, the model being estimated is a two-level regression model, in which items are nested within persons. `itemnum` is a fixed level-1 predictor of the level-2 variable, `response`, and the `itemnum` variable itself is in fact an indicator of the latent variable of item difficulty. If there are _k_ items in the input file, BLIMP creates _k-1_ dummy code variables to represent the items.

The model can be specified as follows:

Y~_ip_~ = {B~_0_~ + B~_1_~(D~_1ip_~) + … + B~_k-1_~(D~_k-1ip_~)} + U~_p_~ + E~_ip_~

The expression within the curly braces `{}` is the _fixed_ component of the model, and the rest of the terms constitute the _random_ component of the model. In addition:

 * Y~_ip_~: predicted score on item _i_ for person _p_;
 * B~_0_~: a fixed intercept, which BLIMP sets to the mean score of item 1 across persons;
 * B~_1_~ ... B~_k-1_~: fixed slopes (one for each of the _k-1_ dummy variables), which BLIMP sets to the difference between the mean score of item 1 (i.e., B~_0_~) and the mean score of the item represented by a specific dummy code variable (e.g., B~_5_~ = mean(item 6) - mean(item 1)). These slopes represent item difficulty. 
     + Note that because `itemnum` is a fixed predictor, the parameter being estimated is the item mean. The use of _intercept_ and _slope_ to refer to the item mean (and differences between item means) reflects the visualization of a linear regression model as a line specified by its slope and _y_-intercept.
     + If `itemnum` were entered into the model as a _random_ predictor, BLIMP would estimate items means _and_ variances. 
 * D~_1ip_~ ... D~_k-1ip_~: dummy code variables (fixed predictors in the model);
 * U~_p_~: random intercept term that captures the influence of person ability on Y~_ip_~, above and beyond the variance explained by item difficulty (i.e., the fixed component of the regression model);
 * E~_ip_~: random error at the level of individual item scores.
 
We should note that in this model, items can vary in difficulty relative to each other, but not across persons. This is what is meant by a _fixed_ slope. For example, slopes B~_2_~ and B~_5_~ can differ from each other, reflecting real differences in item difficulties (the latent variables to which these slopes refer). But the value of B~_2_~ is fixed because it does not vary across persons, just as item difficulty is expected to a be constant among persons of varying ability.

More generally:

* A _fixed_ parameter (e.g,. slope or intercept) _does not vary_ across persons.
  + BLIMP estimates _only the mean_ of a fixed parameter.
* A _random_ parameter _may vary_ across persons.
  + BLIMP estimates the mean _and_ variance of a random parameter.

The `response ~ itemnum` model yields a high degree of precision in imputed data sets, because it represents the actual state of affairs in which item difficulties are independent of one another. This model is therefore preferred in estimating missing data, especially in planned missing data designs (e.g., linked test forms) where the rate of missingness is high (e.g., > 20%). However, the `response ~ itemnum` model is computationally intensive, and may result in unacceptably lengthy processing times, especially when the input data set comprises more than 100 items. In these latter applications, we can use alternative regression models that run more efficiently (see appendix).
```{r BLIMP_example, echo=8, eval=FALSE}
```
`SEED` sets BLIMP's random-number generator so that the final output is identical each time the script is run. `BURN` specifies the number of iterations that are run prior to saving the first imputed data set. As described above, `BURN` is initially set at 1000 for the diagnostic run, and this value is adjusted as needed to until PSR reaches the acceptable threshold. This adjusted value is then used for the imputation run.

`ITERATIONS` controls how many iterations are run after completing burn-in. For the present purpose, which is generating an imputed data set, `ITERATIONS` is set to 1. If the project required regression parameters as explicit output, `ITERATIONS` would be set to at least 1000 to ensure stable estimates.
```{r BLIMP_example, echo=9:11, eval=FALSE}
```
`OPTIONS` and `SAVE` are the two BLIMP commands that are set differently for the diagnostic and imputation runs. For the diagnostic run, `SAVE` is toggled off, and `OPTIONS` is run to generate the PSR table that is used to determine the optimal burn-in interval. For the imputation run, `OPTIONS` is toggled off, and `SAVE` is run to save the imputed data set. The `separate` argument indicates that each imputed data set is to be saved as a separate file (as opposed to being stacked on top of one another in a single file). The file name on `SAVE` requires an `*`, which allows BLIMP to append numerical suffixes on multiple imputed data files. (`*` is always used, even in this example, which yields only a single imputed data set)
```{r BLIMP_example, echo=12:13, eval=FALSE}
```

<br>

### Reformat imputed data set for downstream analysis

BLIMP writes the imputed data set as a `.csv`, in a tall format without column names. This R code restores the imputed data to its original input structure for subsequent analysis.

###### VALID CODE TO RUN

```{r reformat_impute, eval=FALSE}
impute_name <- c("{FILE-NAME}")
impute_path <- c("{FILE-PATH}")

temp1 <- suppressMessages(
  read_csv(
    here(
    str_c(impute_path, impute_name, ".csv")
  ),
    col_names = F))
names(temp1) <- c("id", "item", "response")
temp2 <- temp1 %>% 
  pivot_wider(
    id_cols = id,
    names_from = item,
    values_from = response
  )
names(temp2) <- names(input_orig)

NA_count <- sum(temp2 == 999)
NA_count

write_csv(temp2, here(
  str_c(
    'OUTPUT-FILES/',
    file_name,
    '-noMiss.csv'
  )
))
```

<br>

###### COMMENTED SNIPPETS
The imputed data file `BLIMP-output1.csv` has no column names, so `read_csv()` must be called with the `col_names = F` argument (otherwise, the first row of data will be used as column names). The imputed data file is read into an R object called `temp1`. Column names are applied to `temp1` from a character vector using `base::names()`.
```{r reformat_impute, echo=1:10, eval=FALSE}
```
The data object `temp1` is a tall table in which `item`s and their associated `response`s are nested within each person `id` number, as in the following example:

###### Before

id            | item          | response
------------- | ------------- | -------------
1001          | i01           | 2
1001          | i02           | 2
1001          | i03           | 3
1001          | i04           | 1
1002          | i01           | 4
1002          | i02           | 1
1002          | i03           | 4
1002          | i04           | 2
1003          | i01           | 3
1003          | i02           | 2
1003          | i03           | 3
1003          | i04           | 4

To restore this data object to a wide format, we call `tidyr::pivot_wider()`. Its first argument `id_cols = id` collapses the multiple duplicate rows of `id` into a single row for each `id` number. `names_from = item` indicates that the values of the `item` column are used to name new columns going left-to-right across the transformed table. `values_from = response` indicates that values from the `response` column are used to fill the cells of the newly restored item columns. In the restructured table, each `id` row holds all of the item responses for a single person, as in the original input file.

The transformed table appears as in the example below:

###### After

id            | i01           | i02           | i03           | i04
------------- | ------------- | ------------- | ------------- | -------------
1001          | 2             | 2             | 3             | 1
1002          | 4             | 1             | 4             | 2
1003          | 3             | 2             | 3             | 4

Thus, `pivot_wider` restores the imputed data set to the same format as original input (which contained missing data). In this sense, `pivot_wider` is the inverse of `pivot_longer`, which was used in earlier code to transform the original input into the multi-level (nested) format required by BLIMP.

In the remainder of this code chunk, `names()` is used to reapply the column names of the original input. The code verifies that the count of `NA` (now coded as `999`) is 0, and writes the final output to `.csv`. The output has no missing data and is thus ready for downstream analysis.

```{r reformat_impute, echo=11:28, eval=FALSE}
```
<br>

### Appendix: Alternate regression models

As noted above, we prefer the `response ~ itemnum` model for its accuracy, but with some larger data sets, it may lead to unacceptably length processing times.

When the rate of missingness is small (< 2%), we can use the `response ~` model. This is a _null_ model, so called because it includes no predictor variables. It is analogous to a factor-analysis model in which all items load on a single latent variable, with identical factor loadings. This common factor loading essentially aggregates the difficulty values of all items into a single value. Thus the actual state of affairs in which items vary in difficulty is not represented in this model. Instead, the model represents person differences by the single factor score that varies across persons, but not across items. With this model, BLIMP runs will converge quickly, even with vary large data sets.

With tests that have a subscale structure, we can employ a model that represents subscale score as a random predictor of item response. This model is a useful compromise between the more accurate, computationally intensive`response ~ itemnum` model, and the less accurate, computationally efficient `response ~ ` model.

Here is an example of R code for transforming a wide-format input file into a long-format data object suitable for BLIMP input. This example includes calls of `mutate()` and `case_when()` that create an integer `scale` variable to code item-to-subscale mapping.

```
input_long <- input_orig %>%
  pivot_longer(cols = -ID,
               names_to = "item",
               values_to = "response") %>%
  mutate(
    scale = case_when(
      item %in% item[1:50] ~ 1, 
      item %in% item[51:84] ~ 2, 
      item %in% item[85:114] ~ 3, 
      item %in% item[115:185] ~ 4, 
      item %in% item[186:206] ~ 5, 
      item %in% item[207:251] ~ 6, 
      item %in% item[252:293] ~ 7, 
      item %in% item[294:343] ~ 8, 
      item %in% item[344:363] ~ 9, 
      item %in% item[364:388] ~ 10, 
      item %in% item[389:438] ~ 11, 
      item %in% item[439:459] ~ 12, 
      item %in% item[460:502] ~ 13, 
      item %in% item[503:544] ~ 14, 
    ), 
    across(item, ~ str_sub(., 2, 4))) %>% 
  relocate(scale, .after = "ID")
```
Recall that in the long data format, items are nested within persons. In the first argument to `case_when()`, the predicate `item %in% item[1:50]` returns `TRUE`, for the first 50 rows of items, within each person. `~ 1` indicates that these rows will be coded `1` on `scale`, to represent their assignment to the first subscale. Analogous arguments assign items to 13 additional subscales, and the coding repeats anew within each set of person rows (i.e., rows with identical values on `ID`).

Once subscale assignment is coded in this manner, we can use the `response ~  scalenum | scalenum` model to incorporate subscale score as a random predictor of item response. Here are select lines from a BLIMP script that includes this model.

```
VARIABLES: id scalenum itemnum response;
ORDINAL: response;
NOMINAL: scalenum;
FIXED: scalenum;
CLUSTERID: id;
MISSING: 999;
MODEL: response ~ scalenum | scalenum;
```
On the `MODEL` line, we specify that `response` is regressed on `scalenum`, and by listing `scalenum` a second time to the right of the vertical pipe `|` symbol, we designate it as a random predictor. Note that `scalenum` (instead of `itemnum`) is now listed on the `NOMINAL` and `FIXED` lines.

In general, for a test with _k_ subscales, the `response ~ scalenum | scalenum` model is represented as:

Y~_ip_~ = (B~_0_~ + U~_p_~) + (B~_1_~ + U~_1p_~)(D~_1ip_~) + … + ( B~_k-1_~ + U~_k-1p_~)(D~_k-1ip_~) + E~_ip_~

Where:

 * Y~_ip_~: predicted score on item _i_ for person _p_;
 * (B~_0_~ + U~_p_~): random intercept, composed of:
   + B~_0_~: mean score of subscale 1 across persons;
   + U~_p_~: random term that represents person-specific ability;
 * (B~_k_~ + U~_kp_~): random slopes, composed of:
   + B~_k_~: mean difference, across persons, between subscale 1 score and subscale _k_ score;
   + U~_kp_~: random term that represents person-specific ability, as expressed by each person's score on subscale _k_;
 * D~_kp_~ ... D~_k-1ip_~: dummy code variables;
 * E~_ip_~: random error at the level of individual item scores.

Note the absence of curly braces `{}`. Because `scalenum` is a random predictor, the resulting regression equation lacks a fixed component. As noted above, each term in the equation is made random by the inclusion of the U term that denotes person-specific ability.

The `response ~ scalenum | scalenum` model is less precise than the `response ~ itemnum` model, simply because the former does not include `itemnum` as predictor. As a result, it does not directly incorporate variance due to item difficulty into the estimate of Y~_ip_~.

However, we can think of `scalenum` as a proxy for item difficulty. Subscale scores represent aggregate measures of the difficulties of their component items. By entering `scalenum` as a random predictor, we allow between-person variance in subscale scores to contribute to the estimate of Y~_ip_~. Thus, variance in item difficulty is incorporated indirectly, through the more coarsed-grained proxy of subscale score.

The`response ~ scalenum | scalenum` model is thus more precise than the `response ~ `, which includes neither item difficulties nor subscales scores as predictors of Y~_ip_~.



